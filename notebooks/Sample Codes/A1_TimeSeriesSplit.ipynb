{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fda55b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kewei\\AppData\\Roaming\\Python\\Python310\\site-packages\\yfinance\\base.py:48: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  _empty_series = pd.Series()\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold 129: 0.56\n",
      "Accuracy for fold 254: 0.42\n",
      "Accuracy for fold 379: 0.66\n",
      "Accuracy for fold 504: 0.58\n",
      "Accuracy for fold 629: 0.70\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Downloading the data\n",
    "ticker_symbol = \"CL=F\"\n",
    "oil_data = yf.download(ticker_symbol, start=\"2020-01-01\", end=\"2023-01-01\")\n",
    "\n",
    "# 1. Prepare the Data\n",
    "# Calculate daily returns\n",
    "oil_data['Return'] = oil_data['Close'].pct_change()\n",
    "# Create the binary target variable\n",
    "oil_data['Y'] = (oil_data['Return'] >= 0).astype(int)\n",
    "\n",
    "# Feature Engineering: using OHLC and Volume as features\n",
    "features = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "# In fact, this is not the correct way of using OHLC and volume,\n",
    "# It is better to use ratios, not raw values to avoid overfitting.\n",
    "# Here, the purpose is to provide you a sample code that TimeSeriesSplit works.\n",
    "X = oil_data[features]\n",
    "y = oil_data['Y']\n",
    "\n",
    "# Drop the first row as it will have NaN for return\n",
    "X = X.iloc[1:]\n",
    "y = y.iloc[1:]\n",
    "\n",
    "# 2. Time Series Split\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # 3. Model Training and Tuning\n",
    "    # Define the model\n",
    "    model = lgb.LGBMClassifier()\n",
    "    \n",
    "    # Define the parameter grid\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'max_depth': [3, 5]\n",
    "    }\n",
    "    \n",
    "    # GridSearchCV\n",
    "    gsearch = GridSearchCV(estimator=model, param_grid=param_grid, cv=TimeSeriesSplit(n_splits=3).split(X_train), scoring='accuracy')\n",
    "    gsearch.fit(X_train, y_train)\n",
    "    \n",
    "    # Best model\n",
    "    best_model = gsearch.best_estimator_\n",
    "    \n",
    "    # 4. Model Evaluation\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy for fold {train_index[-1]}: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab680ea",
   "metadata": {},
   "source": [
    "# Differences between Time Series Split and 5-Fold Cross-Validation\n",
    "\n",
    "When dealing with time series data, the way we validate our model is crucial because time series data have a time dimension, which introduces temporal dependencies between observations. This characteristic makes the validation process fundamentally different from that used for cross-sectional data. Let's delve into the differences between Time Series Split and traditional K-Fold Cross-Validation, specifically focusing on 5-Fold Cross-Validation for comparison.\n",
    "\n",
    "## 5-Fold Cross-Validation (K-Fold Cross-Validation)\n",
    "\n",
    "In K-Fold Cross-Validation, the data is randomly divided into 'K' folds. For each fold 'i':\n",
    "- The fold 'i' is used as the validation set.\n",
    "- The remaining 'K-1' folds are used as the training set.\n",
    "- The model is trained on the 'K-1' folds and evaluated on the 'i-th' fold.\n",
    "- This process is repeated 'K' times, each time with a different fold used as the validation set.\n",
    "\n",
    "### Characteristics:\n",
    "- Each data point gets to be in a validation set exactly once, and gets to be in a training set 'K-1' times.\n",
    "- The order of the data is not preserved (random splitting).\n",
    "\n",
    "![5-Fold Cross-Validation](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)\n",
    "\n",
    "_Image Source: scikit-learn.org_\n",
    "\n",
    "## Time Series Split\n",
    "\n",
    "Time Series Split is a variation of cross-validation used for time-ordered data. It's a more appropriate choice when you're working with time series data. In Time Series Split:\n",
    "- The dataset is split into 'K' consecutive folds.\n",
    "- Unlike in K-Fold Cross-Validation, the validation set for each fold consists of data points that come after all the data points in the training set, preserving the temporal order of observations.\n",
    "\n",
    "### Characteristics:\n",
    "- Ensures that the training set always precedes the validation set.\n",
    "- Prevents the model from seeing future data at the training time.\n",
    "- More suitable for time series data where temporal ordering matters.\n",
    "\n",
    "![Time Series Split](https://miro.medium.com/max/1400/1*2-zaRQ-dsv8KWxOlzc8VaA.png)\n",
    "\n",
    "_Image Source: Towards Data Science (miro.medium.com)_\n",
    "\n",
    "## Key Differences\n",
    "\n",
    "1. **Randomization**: \n",
    "   - 5-Fold Cross-Validation randomly splits the data, ignoring the time component.\n",
    "   - Time Series Split preserves the order of data, respecting the time component.\n",
    "\n",
    "2. **Data Leakage**:\n",
    "   - 5-Fold Cross-Validation can cause data leakage in time series datasets if future data is used to predict past events.\n",
    "   - Time Series Split prevents data leakage by ensuring the model is only trained on past data to predict future data.\n",
    "\n",
    "3. **Model Evaluation**:\n",
    "   - In time series forecasting, model performance can vary significantly depending on the period being predicted. Time Series Split allows the model's performance to be evaluated on different periods, reflecting more realistic forecasting scenarios.\n",
    "   - 5-Fold Cross-Validation evaluates the model on random subsets of data, which may not provide an accurate assessment of the model's forecasting ability over time.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Choosing the right cross-validation technique is crucial in time series analysis to avoid data leakage and ensure that the model is evaluated in a manner that reflects its practical use. Time Series Split is typically preferred over K-Fold Cross-Validation for time series data due to its ability to handle the temporal structure of the data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
